<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>智慧邊緣運算於即時電子感測系統之應用與實現 — 以即時人形與物件偵測為例</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif, "Microsoft JhengHei", "PingFang TC", "Helvetica Neue", Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
        }
        header {
            background-color: #333;
            color: white;
            padding: 1em 0;
            text-align: center;
        }
        header h1 {
            margin: 0;
            font-size: 1.8em;
        }
        nav {
            background-color: #444;
            padding: 0.5em 0;
        }
        nav ul {
            list-style-type: none;
            padding: 0;
            margin: 0;
            display: flex;
            justify-content: center;
            flex-wrap: wrap; /* 允許換行 */
        }
        nav ul li {
            margin: 5px 10px;
        }
        nav ul li a {
            color: white;
            text-decoration: none;
            padding: 10px 15px;
            display: block;
            border-radius: 5px;
            transition: background-color 0.3s;
        }
        nav ul li a:hover, nav ul li a.active {
            background-color: #555;
        }
        .content-section {
            display: none; /* 預設隱藏所有內容區塊 */
            padding: 20px;
            margin: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #f9f9f9;
        }
        .content-section.active {
            display: block; /* 顯示被選中的內容區塊 */
        }
        .content-section h2 {
            color: #333;
            border-bottom: 2px solid #4CAF50;
            padding-bottom: 0.3em;
            margin-top: 0;
        }
        .content-section h3 {
            color: #444;
            margin-top: 1.5em;
        }
        .content-section h4 {
            color: #555;
            margin-top: 1em;
        }
        .content-section p, .content-section ul, .content-section ol {
            margin-bottom: 1em;
        }
        .content-section ul li, .content-section ol li {
            margin-bottom: 0.5em;
        }
        pre {
            background-color: #eee;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
        }
        .placeholder-text {
            color: #888;
            font-style: italic;
        }

        /* 針對封面頁面的特殊樣式 */
        #cover-page-content {
            text-align: center;
        }
        #cover-page-content h2 {
            font-size: 2em;
            margin-bottom: 1em;
            border-bottom: none; /* 封面標題通常不需要底線 */
        }
        #cover-page-content p {
            font-size: 1.2em;
            margin-bottom: 0.5em;
        }

    </style>
</head>
<body>

    <header>
        <h1>智慧邊緣運算於即時電子感測系統之應用與實現 — 以即時人形與物件偵測為例</h1>
    </header>

    <nav>
        <ul id="main-nav">
            <li><a href="#cover-page" data-target="cover-page-content">封面 (Cover Page)</a></li>
            <li><a href="#abstract" data-target="abstract-content">摘要 (Abstract)</a></li>
            <li><a href="#acknowledgements" data-target="acknowledgements-content">謝誌 (Acknowledgements)</a></li>
            <li><a href="#table-of-contents" data-target="toc-content">目錄 (Table of Contents)</a></li>
            <li><a href="#list-of-figures" data-target="lof-content">圖目錄 (List of Figures)</a></li>
            <li><a href="#list-of-tables" data-target="lot-content">表目錄 (List of Tables)</a></li>
            <li><a href="#chapter1" data-target="chapter1-content">第一章 緒論</a></li>
            <li><a href="#chapter2" data-target="chapter2-content">第二章 文獻探討</a></li>
            <li><a href="#chapter3" data-target="chapter3-content">第三章 系統設計與架構</a></li>
            <li><a href="#chapter4" data-target="chapter4-content">第四章 系統實現與實驗結果</a></li>
            <li><a href="#chapter5" data-target="chapter5-content">第五章 結論與未來展望</a></li>
            <li><a href="#references" data-target="references-content">參考文獻</a></li>
            <li><a href="#appendices" data-target="appendices-content">附錄</a></li>
            <li><a href="#team" data-target="team-content">專題團隊</a></li>
        </ul>
    </nav>

    <div id="content-container">
        <div id="cover-page-content" class="content-section">
            <h2>專題題目：智慧邊緣運算於即時電子感測系統之應用與實現 — 以即時人形與物件偵測為例</h2>
            <p>指導老師：XXX 教授</p>
            <p>組員姓名、學號：王小明 (F12345678)</p>
            <p>執行期間/日期：中華民國 113 年 9 月 至 中華民國 114 年 5 月</p>
        </div>

        <div id="abstract-content" class="content-section">
            <h2>摘要 (Abstract)</h2>
            <p>本專題旨在設計並實現一套基於智慧邊緣運算的即時電子感測系統，專注於透過攝影機進行即時人形與特定物件偵測。傳統雲端AI影像分析系統常面臨延遲、頻寬依賴及隱私洩漏等問題。為解決這些挑戰，本系統將影像擷取、預處理、AI模型推論等運算任務直接在邊緣裝置（如NVIDIA Jetson Nano或Raspberry Pi）上完成。系統採用了輕量級的卷積神經網路模型（如YOLOvX-tiny或MobileNet-SSD），並針對邊緣裝置進行了優化。實驗結果顯示，本系統能夠在[具體幀率，例如：15 FPS]下達到[具體準確率，例如：85% mAP]的人形與物件偵測效能，且反應延遲低於[具體毫秒數，例如：100ms]。本研究驗證了邊緣運算在即時影像感測應用中的可行性與優勢，為智慧監控、自動駕駛輔助等領域提供了具參考價值的解決方案。</p>
        </div>

        <div id="acknowledgements-content" class="content-section">
            <h2>謝誌 (Acknowledgements)</h2>
            <p>感謝指導老師 XXX 教授在本專題研究期間的悉心指導與寶貴建議，使我們得以順利完成此項研究。同時感謝實驗室學長姐在技術問題上的無私協助，以及家人朋友的支持與鼓勵...等。</p>
        </div>

        <div id="toc-content" class="content-section">
            <h2>目錄 (Table of Contents)</h2>
            <p class="placeholder-text">[此處將自動或手動生成目錄]</p>
            <ul>
                <li>封面 (Cover Page)</li>
                <li>摘要 (Abstract)</li>
                <li>謝誌 (Acknowledgements)</li>
                <li>目錄 (Table of Contents)</li>
                <li>圖目錄 (List of Figures)</li>
                <li>表目錄 (List of Tables)</li>
                <li>第一章 緒論
                    <ul>
                        <li>1.1 研究背景與動機</li>
                        <li>1.2 研究目的</li>
                        <li>1.3 研究範圍與限制</li>
                        <li>1.4 報告架構</li>
                    </ul>
                </li>
                <li>第二章 文獻探討
                    <ul>
                        <li>2.1 邊緣運算 (Edge Computing)</li>
                        <li>2.2 即時電子感測技術 (Real-time Electronic Sensing Technology)</li>
                        <li>2.3 應用於邊緣裝置的人工智慧演算法</li>
                        <li>2.4 本章小結</li>
                    </ul>
                </li>
                <li>第三章 系統設計與架構
                    <ul>
                        <li>3.1 系統整體架構</li>
                        <li>3.2 硬體平台設計與選擇</li>
                        <li>3.3 軟體流程設計</li>
                        <li>3.4 預期應用場景描述</li>
                    </ul>
                </li>
                <li>第四章 系統實現與實驗結果
                    <ul>
                        <li>4.1 實驗環境建置</li>
                        <li>4.2 功能驗證與測試</li>
                        <li>4.3 效能評估指標與方法</li>
                        <li>4.4 實驗結果與分析</li>
                    </ul>
                </li>
                <li>第五章 結論與未來展望
                    <ul>
                        <li>5.1 結論</li>
                        <li>5.2 研究限制與檢討</li>
                        <li>5.3 未來展望</li>
                    </ul>
                </li>
                <li>參考文獻 (References)</li>
                <li>附錄 (Appendices)</li>
                <li>專題團隊</li>
            </ul>
        </div>

        <div id="lof-content" class="content-section">
            <h2>圖目錄 (List of Figures)</h2>
            <p class="placeholder-text">[此處將自動或手動生成圖目錄]</p>
        </div>

        <div id="lot-content" class="content-section">
            <h2>表目錄 (List of Tables)</h2>
            <p class="placeholder-text">[此處將自動或手動生成表目錄]</p>
        </div>

        <div id="chapter1-content" class="content-section">
            <h2>第一章 緒論 (Chapter 1: Introduction)</h2>
            <h3>1.1 研究背景與動機</h3>
            <p>隨著物聯網(IoT)與人工智慧(AI)技術的飛速發展，智慧化的電子感測系統在各領域的應用日益廣泛，例如智慧家庭、智慧城市、工業自動化等。傳統的感測系統多將原始數據上傳至雲端進行AI分析，但此架構面臨諸多挑戰：(1) 高延遲：數據往返雲端造成不可避免的延遲，不適用於如自動駕駛、即時警報等對反應速度有嚴苛要求的場景。(2) 高頻寬消耗：大量原始感測數據（尤其是影像數據）的傳輸對網路頻寬造成巨大壓力。(3) 隱私安全風險：敏感數據上傳雲端增加了洩漏的風險。(4) 網路依賴性：一旦網路中斷，系統便可能癱瘓。</p>
            <p>邊緣運算(Edge Computing)作為一種新興的運算 패러다임，將運算任務從雲端下沉至靠近數據源的邊緣裝置執行，有望解決上述問題。本專題旨在探索將智慧邊緣運算技術應用於攝影機等電子感測器，實現即時的人形與物件偵測，期望能為需要快速反應與保障數據隱私的應用場景提供高效能的解決方案。</p>
            <h3>1.2 研究目的</h3>
            <ul>
                <li>研究並比較適用於邊緣運算裝置的輕量級物件偵測AI模型。</li>
                <li>設計並搭建一套整合攝影機感測模組與邊緣運算平台（如NVIDIA Jetson Nano或Raspberry Pi）的硬體系統。</li>
                <li>在選定的邊緣運算平台上，成功佈署並優化AI模型，實現即時的人形與[您選擇的特定物件，如：車輛、包裹等]偵測功能。</li>
                <li>評估所開發系統的偵測準確率、推論速度（幀率）、系統延遲及功耗等關鍵效能指標。</li>
            </ul>
            <h3>1.3 研究範圍與限制</h3>
            <p><strong>範圍：</strong>本專題將聚焦於視覺感測，使用單一攝影機作為主要的感測輸入。AI模型將選用[具體模型，如YOLOvX-tiny或MobileNet-SSD等]進行研究與佈署。邊緣運算平台初步選定為[具體平台，如NVIDIA Jetson Nano]。偵測目標主要為人形及[1-2種特定物件]。</p>
            <p><strong>限制：</strong>由於時間與資源限制，本專題可能不涉及複雜場景下的多攝影機融合、大規模模型訓練或極端環境（如極低光源、惡劣天氣）下的效能優化。AI模型的訓練將主要基於公開資料集，並可能輔以少量自採數據進行微調。</p>
            <h3>1.4 報告架構</h3>
            <p>本報告共分為五章。第一章為緒論，說明研究背景、動機、目的與範圍。第二章為文獻探討，回顧邊緣運算、即時電子感測及相關AI演算法的技術發展。第三章詳述系統設計與架構，包含硬體選型、軟體流程與AI模型設計。第四章呈現系統實現過程與實驗結果分析。第五章為結論與未來展望。</p>
        </div>

        <div id="chapter2-content" class="content-section">
            <h2>第二章 文獻探討 (Chapter 2: Literature Review)</h2>
            <h3>2.1 邊緣運算 (Edge Computing)</h3>
            <h4>2.1.1 邊緣運算的定義、核心概念</h4>
            <p>與雲端運算、霧運算的比較、典型架構（如MEC多接取邊緣運算）。</p>
            <h4>2.1.2 邊緣運算的優勢與挑戰</h4>
            <p>優勢（低延遲、隱私保護、節省頻寬、離線運作能力）與挑戰（資源限制、模型輕量化、安全性、管理複雜性）。</p>
            <h4>2.1.3 主流邊緣運算平台比較</h4>
            <p>例如：NVIDIA Jetson系列 - GPU加速能力強；Raspberry Pi - 性價比高、社群支援廣；Google Coral - TPU加速；FPGA方案 - 可客製化高。列舉其硬體規格、支援的AI框架(TensorFlow Lite, PyTorch Mobile, TensorRT等)。</p>

            <h3>2.2 即時電子感測技術 (Real-time Electronic Sensing Technology)</h3>
            <h4>2.2.1 視覺感測技術</h4>
            <p>CMOS/CCD感測器原理、影像擷取介面（MIPI CSI、USB）、鏡頭參數（焦距、光圈）。</p>
            <h4>2.2.2 即時影像處理</h4>
            <p>影像擷取、預處理（縮放、去噪、色彩空間轉換）的即時性要求。</p>
            <h4>2.2.3 應用案例</h4>
            <p>智慧監控、ADAS中的視覺感測。</p>

            <h3>2.3 應用於邊緣裝置的人工智慧演算法</h3>
            <h4>2.3.1 物件偵測演算法發展</h4>
            <p>從R-CNN系列到SSD、YOLO系列。特別關注適用於邊緣裝置的輕量級模型，如YOLOv3-tiny, YOLOv4-tiny, YOLOv5s, YOLOv7-tiny, MobileNets (v1, v2, v3), SqueezeNet, EfficientDet-Lite等。比較其速度、精度與模型大小。</p>
            <h4>2.3.2 模型壓縮與優化技術</h4>
            <ul>
                <li>剪枝 (Pruning)：移除不重要的權重或神經元。</li>
                <li>量化 (Quantization)：將32位元浮點數權重轉換為8位元整數或其他低位元表示，以減少模型大小和加速推論（如INT8量化）。</li>
                <li>知識蒸餾 (Knowledge Distillation)：用一個大型、複雜的「教師模型」來指導一個小型「學生模型」的訓練。</li>
                <li>神經架構搜索 (Neural Architecture Search - NAS)：自動化設計高效的網路結構。</li>
            </ul>
            <h4>2.3.3 相關應用案例分析</h4>
            <p>分析已有的基於邊緣AI的即時影像辨識系統，其採用的技術方案與達成的效能。</p>

            <h3>2.4 本章小結</h3>
            <p>總結現有技術的優缺點，明確本專題在現有基礎上希望解決的問題或進行的改進。</p>
        </div>

        <div id="chapter3-content" class="content-section">
            <h2>第三章 系統設計與架構 (Chapter 3: System Design and Architecture)</h2>
            <h3>3.1 系統整體架構</h3>
            <p>繪製系統方塊圖，例如：[攝影機模組] -> [影像擷取介面 (CSI/USB)] -> [邊緣運算平台 (e.g., Jetson Nano)] -> [影像預處理模組 (OpenCV)] -> [AI推論引擎 (TensorRT/TF Lite)] -> [後處理模組 (NMS, 結果解析)] -> [輸出模組 (顯示、網路傳輸、GPIO控制警報)]。</p>
            <p>說明各模組間的數據流和控制信號。</p>
            <p class="placeholder-text">[此處可插入系統方塊圖圖片]</p>

            <h3>3.2 硬體平台設計與選擇</h3>
            <h4>3.2.1 邊緣運算主控單元</h4>
            <p>選擇 [NVIDIA Jetson Nano Developer Kit B01]。理由：具備四核心ARM CPU及128核Maxwell GPU，支援CUDA與TensorRT，適合AI視覺應用；擁有豐富的I/O接口；社群資源豐富。</p>
            <h4>3.2.2 感測器模組</h4>
            <p>選擇 [Raspberry Pi Camera Module V2 (IMX219)]。理由：800萬像素，支援1080p30影像，MIPI CSI介面直接連接Jetson Nano，驅動方便。</p>
            <h4>3.2.3 電源管理</h4>
            <p>使用5V/4A Type-C電源供應器，確保系統穩定運作。</p>
            <h4>3.2.4 其他週邊</h4>
            <p>散熱風扇、螢幕、鍵盤滑鼠 (開發階段使用)。</p>

            <h3>3.3 軟體流程設計</h3>
            <h4>3.3.1 資料擷取與預處理</h4>
            <p>使用OpenCV擷取攝影機影像。預處理步驟包括：影像縮放至模型輸入尺寸 (例如416x416或300x300)、色彩通道轉換 (BGR to RGB)、歸一化等。</p>
            <h4>3.3.2 AI模型選擇、訓練與優化</h4>
            <p><strong>模型選擇：</strong>選擇 [YOLOv7-tiny]。理由：在速度與精度之間有較好的平衡，適合邊緣部署。</p>
            <p><strong>訓練：</strong>使用[公開資料集，如COCO或PASCAL VOC]進行預訓練，或針對特定應用場景使用[自建或特定領域資料集]進行遷移學習/微調。說明訓練環境（硬體、框架如PyTorch/TensorFlow）、超參數設定。</p>
            <p><strong>優化與轉換：</strong>將訓練好的模型（如.pt或.h5檔案）轉換為適用於目標平台的格式（如TensorRT engine或.tflite檔案）。說明是否使用量化（如FP16或INT8）以提升速度。</p>
            <h4>3.3.3 邊緣端應用程式邏輯</h4>
            <p>使用Python或C++編寫主程式。流程：循環讀取影像 -> 預處理 -> 模型推論 -> 解析輸出 (bounding box座標、類別、信賴度) -> 後處理 (如非極大值抑制NMS) -> 在影像上繪製結果 -> 顯示/輸出。</p>
            <h4>3.3.4 通訊協定 (若有)</h4>
            <p>若需將結果傳輸至其他裝置或雲端，可設計使用MQTT、HTTP等協定。</p>

            <h3>3.4 預期應用場景描述</h3>
            <p>本系統可應用於家庭安全監控，當攝影機偵測到人形進入警戒區域時，可即時發出警報；或應用於智慧零售，分析進店顧客人形，但為保護隱私，僅在本地處理。</p>
        </div>

        <div id="chapter4-content" class="content-section">
            <h2>第四章 系統實現與實驗結果 (Chapter 4: System Implementation and Experimental Results)</h2>
            <h3>4.1 實驗環境建置</h3>
            <h4>4.1.1 硬體系統實體搭建</h4>
            <p>展示實際連接圖或照片。</p>
            <p class="placeholder-text">[此處可插入硬體連接圖或照片]</p>
            <h4>4.1.2 軟體開發環境</h4>
            <p>Jetson Nano的JetPack SDK版本、CUDA版本、TensorRT版本、OpenCV版本、Python版本及相關函式庫。</p>

            <h3>4.2 功能驗證與測試</h3>
            <h4>4.2.1 各模組功能測試</h4>
            <p>攝影機能否正常擷取影像、預處理是否正確、AI模型推論是否能輸出預期格式的結果。</p>
            <h4>4.2.2 系統整合測試</h4>
            <p>在不同光照條件、不同距離、不同背景下測試系統的偵測效果。</p>

            <h3>4.3 效能評估指標與方法</h3>
            <ul>
                <li><strong>偵測準確率：</strong>使用mAP (mean Average Precision) @ IoU (Intersection over Union) threshold (e.g., 0.5)。使用一組測試影像集進行評估。</li>
                <li><strong>推論速度：</strong>以FPS (Frames Per Second) 或每幀推論時間 (ms) 表示。</li>
                <li><strong>系統延遲：</strong>從影像擷取到結果輸出的總時間。</li>
                <li><strong>功耗：</strong>測量系統在不同工作狀態下的功耗 (W)。</li>
                <li><strong>模型大小:</strong> 部署到邊緣裝置上的模型檔案大小 (MB)。</li>
            </ul>

            <h3>4.4 實驗結果與分析</h3>
            <h4>4.4.1 準確率實驗</h4>
            <p>表格展示在測試集上對不同類別物件的AP及整體mAP。</p>
            <p class="placeholder-text">[此處插入準確率實驗結果表格]</p>
            <h4>4.4.2 速度實驗</h4>
            <p>表格或圖表展示不同模型（若有比較）、不同量化方式下的FPS。</p>
            <p class="placeholder-text">[此處插入速度實驗結果表格/圖表]</p>
            <h4>4.4.3 延遲分析</h4>
            <p>分析各階段（擷取、預處理、推論、後處理）的耗時。</p>
            <p class="placeholder-text">[此處插入延遲分析結果]</p>
            <h4>4.4.4 功耗測試結果</h4>
            <p class="placeholder-text">[此處插入功耗測試結果]</p>
            <h4>4.4.5 結果討論</h4>
            <p>分析結果是否達到預期目標。討論不同參數（如信賴度閾值）對準確率和召回率的影響。與文獻中類似系統的效能進行比較。分析系統的優點與瓶頸。</p>
            <h4>4.4.6 遇到的問題及解決方案</h4>
            <p>例如模型轉換失敗、驅動問題、效能不如預期等，以及如何克服。</p>
        </div>

        <div id="chapter5-content" class="content-section">
            <h2>第五章 結論與未來展望 (Chapter 5: Conclusion and Future Work)</h2>
            <h3>5.1 結論</h3>
            <p>總結本專題完成的主要工作（例如：成功設計並實現了一套基於Jetson Nano的即時人形與物件偵測系統，採用YOLOv7-tiny模型，達到了XX FPS和XX% mAP的效能）。重申本研究的貢獻與價值。</p>
            <h3>5.2 研究限制與檢討</h3>
            <p>說明本研究中未能盡善盡美之處，例如測試場景的單一性、模型對小物件或遮擋物件的偵測能力仍有不足等。</p>
            <h3>5.3 未來展望</h3>
            <ul>
                <li><strong>模型優化：</strong>嘗試更先進的輕量化模型或神經架構搜索技術。</li>
                <li><strong>多感測器融合：</strong>結合如紅外線、雷達等其他感測器提升惡劣環境下的偵測能力。</li>
                <li><strong>功能擴展：</strong>增加如行為分析、目標追蹤等更複雜的功能。</li>
                <li><strong>硬體升級：</strong>評估在更低功耗或更高算力的邊緣AI晶片上的部署效能。</li>
                <li><strong>安全性增強：</strong>研究邊緣AI系統的隱私保護和對抗攻擊防禦機制。</li>
            </ul>
        </div>

        <div id="references-content" class="content-section">
            <h2>參考文獻 (References)</h2>
            <ul>
                <li>Redmon, J., & Farhadi, A. (2018). YOLOv3: An Incremental Improvement. arXiv preprint arXiv:1804.02767.</li>
                <li>Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., ... & Adam, H. (2017). MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv preprint arXiv:1704.04861.</li>
                <li>NVIDIA Jetson Nano Developer Kit User Guide.</li>
                <li>[您參考的其他相關論文、書籍、技術文件網址等]</li>
            </ul>
        </div>

        <div id="appendices-content" class="content-section">
            <h2>附錄 (Appendices)</h2>
            <p class="placeholder-text">（若有）關鍵程式碼片段、詳細電路連接圖、額外的實驗數據表格等。</p>
        </div>

        <div id="team-content" class="content-section">
            <h2>專題團隊</h2>
            <p><strong>指導老師：</strong> XXX 教授</p>
            <p><strong>組員：</strong></p>
            <ul>
                <li>王小明 (學號: F12345678) - [負責項目/分工]</li>
                <li>[組員二姓名] (學號: [組員二學號]) - [負責項目/分工]</li>
                <li>[組員三姓名] (學號: [組員三學號]) - [負責項目/分工] (若有)</li>
            </ul>
            <p class="placeholder-text">[可補充團隊照片或更多資訊]</p>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const navLinks = document.querySelectorAll('#main-nav a');
            const contentSections = document.querySelectorAll('.content-section');

            function showContent(targetId) {
                // 隱藏所有內容區塊
                contentSections.forEach(section => {
                    section.classList.remove('active');
                });
                // 移除所有導航連結的 active 狀態
                navLinks.forEach(link => {
                    link.classList.remove('active');
                });

                // 顯示目標內容區塊
                const targetSection = document.getElementById(targetId);
                if (targetSection) {
                    targetSection.classList.add('active');
                }

                // 設定當前導航連結為 active
                // 使用 attribute selector 來找到對應的 data-target 連結
                const activeLink = document.querySelector(`#main-nav a[data-target="${targetId}"]`);
                if (activeLink) {
                    activeLink.classList.add('active');
                }
            }

            navLinks.forEach(link => {
                link.addEventListener('click', function(event) {
                    event.preventDefault(); // 防止頁面跳轉到錨點
                    const targetId = this.getAttribute('data-target');
                    showContent(targetId);
                    // 如果您希望 URL 也更新 (雖然這裡沒有實際頁面跳轉), 可以取消註解下面這行
                    // window.location.hash = this.getAttribute('href');
                });
            });

            // 檢查 URL hash 並嘗試顯示對應內容 (用於直接訪問帶有 hash 的 URL)
            // 或者預設顯示第一個內容
            let initialTargetId = 'cover-page-content'; // 預設顯示封面
            if (window.location.hash) {
                const hashTarget = window.location.hash.substring(1); // 移除 '#'
                const potentialTarget = document.querySelector(`#main-nav a[href="#${hashTarget}"]`);
                if (potentialTarget) {
                    initialTargetId = potentialTarget.getAttribute('data-target');
                }
            }
            
            // 如果沒有 hash 或 hash 無效，則顯示第一個導航連結的目標
            if (!document.getElementById(initialTargetId) && navLinks.length > 0) {
                 initialTargetId = navLinks[0].getAttribute('data-target');
            }
            showContent(initialTargetId);

        });
    </script>

</body>
</html>